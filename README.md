ğŸ§  Multi DataFrame Agent using LangChain + OpenAI

This project demonstrates how to use LangChain and OpenAIâ€™s LLMs to interact intelligently with multiple Pandas DataFrames.
Instead of writing manual queries, you can ask questions in natural language, and the agent will automatically analyze, combine, and summarize data from multiple sources.

ğŸš€ Features

ğŸ§© Query multiple DataFrames simultaneously.

ğŸ’¬ Ask natural language questions about your datasets.

âš™ï¸ Uses LangChainâ€™s create_pandas_dataframe_agent for reasoning and analysis.

ğŸ¤– Powered by OpenAI GPT models (gpt-4o-mini or similar).

ğŸ“Š Automatically executes safe Pandas code to answer questions.

ğŸ§  Extendable with memory, callbacks, or custom tools.

ğŸ“‚ Project Structure
ğŸ“¦ Multi_dataframe_Agents
 â”£ ğŸ“œ Multi_dataframe_Agents.ipynb   â† Main notebook
 â”£ ğŸ“Š sales.csv                      â† Example dataset (Sales)
 â”£ ğŸ“Š customers.csv                  â† Example dataset (Customers)
 â”— ğŸ“˜ README.md                      â† Documentation (this file)

ğŸ§° Requirements

Install dependencies before running the notebook:

pip install langchain langchain-openai pandas python-dotenv


Youâ€™ll also need an OpenAI API key:

export OPENAI_API_KEY="your_api_key_here"


Or create a .env file with:

OPENAI_API_KEY=your_api_key_here

ğŸ§© How It Works

Import Dependencies

from langchain.agents import create_pandas_dataframe_agent
from langchain_openai import ChatOpenAI
import pandas as pd


Load Multiple DataFrames

df_sales = pd.read_csv("sales.csv")
df_customers = pd.read_csv("customers.csv")


Initialize the LLM

llm = ChatOpenAI(model="gpt-4o-mini", temperature=0)


Create the Agent

agent = create_pandas_dataframe_agent(
    llm,
    [df_sales, df_customers],
    verbose=True
)


Ask Questions in Natural Language

agent.run("Which customer had the highest sales in 2024?")
agent.run("Show top 3 customers by total revenue.")

ğŸ§  How It Works (Under the Hood)

LangChain gives the LLM access to tools like Pandas DataFrames.

The LLM:

Reads metadata about your DataFrames (columns, sample rows).

Writes Python code to answer your query.

Executes it safely and returns the result.

This is an example of a Tool-Using Agent in LangChain.

ğŸª„ Key Concepts to Remember
Concept	Description
LLM (Large Language Model)	Understands and generates human-like text.
LangChain	Framework that lets LLMs use external tools, APIs, and data.
Pandas DataFrame Agent	Allows the LLM to query structured data.
Tool-Using Agent	The model uses Pandas as a tool to execute code.
RAG (Retrieval-Augmented Generation)	Not used here, but similar concept for text-based data.
Memory	Can store past conversation context (optional).
ğŸ“ˆ Example Questions You Can Ask

â€œWhich customer spent the most money in 2024?â€

â€œFind total sales by region and sort descending.â€

â€œShow customers who purchased both Product A and Product B.â€

â€œCompare 2023 vs 2024 total sales growth.â€

ğŸ”§ Extensions

You can extend this notebook by:

Adding more DataFrames (finance, marketing, etc.)

Integrating Conversation Memory for chat-style use:

from langchain.memory import ConversationBufferMemory


Tracking and debugging with LangSmith callbacks.

Deploying it as a Streamlit app for interactive querying.
